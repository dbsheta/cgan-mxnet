{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CGAN using MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import mxnet.gluon as gluon\n",
    "from mxnet.gluon import nn\n",
    "import mxnet.ndarray as nd\n",
    "from mxnet import autograd\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "latent_z_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhoomilbsheta/deepl/lib/python3.6/site-packages/mxnet/gluon/data/vision.py:118: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  label = np.fromstring(fin.read(), dtype=np.uint8).astype(np.int32)\n",
      "/Users/dhoomilbsheta/deepl/lib/python3.6/site-packages/mxnet/gluon/data/vision.py:122: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data = np.fromstring(fin.read(), dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "def transform(data, label):\n",
    "    return nd.transpose(data.astype(np.float32), (2,0,1))/255, label.astype(np.float32)\n",
    "\n",
    "test_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(gluon.HybridBlock):\n",
    "    def __init__(self, n_dims=128, **kwargs):\n",
    "        super(Generator, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.deconv_z = nn.Conv2DTranspose(n_dims * 2, 4, 1, 0)\n",
    "            self.deconv_label = nn.Conv2DTranspose(n_dims * 2, 4, 1, 0)\n",
    "            self.deconv2 = nn.Conv2DTranspose(n_dims * 2, 4, 1, 0)\n",
    "            self.deconv3 = nn.Conv2DTranspose(n_dims, 4, 2, 1)\n",
    "            self.deconv4 = nn.Conv2DTranspose(1, 4, 2, 1)\n",
    "            \n",
    "            self.bn_z = nn.BatchNorm()\n",
    "            self.bn_label = nn.BatchNorm()\n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            self.bn3 = nn.BatchNorm()\n",
    "    \n",
    "    \n",
    "    def hybrid_forward(self, F, x, y):\n",
    "        x = F.relu(self.bn_z(self.deconv_z(x)))\n",
    "        \n",
    "        y = F.expand_dims(y, axis=2)\n",
    "        y = F.expand_dims(y, axis=2)\n",
    "        y = F.relu(self.bn_label(self.deconv_label(y)))\n",
    "        \n",
    "        z = F.concat(x, y, dim=1)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.deconv2(z)))\n",
    "        x = F.relu(self.bn3(self.deconv3(x)))\n",
    "        x = F.tanh(self.deconv4(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def save(filename):\n",
    "        self.save_params(filename)\n",
    "        \n",
    "    def load(filename, ctx):\n",
    "        self.load_params(filename, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(gluon.HybridBlock):\n",
    "    def __init__(self, n_dims=128, **kwargs):\n",
    "        super(Discriminator, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.conv1 = nn.Conv2D(n_dims, 4, 2, 1)\n",
    "            self.conv2 = nn.Conv2D(n_dims * 2, 4, 2, 1)\n",
    "            self.conv3 = nn.Conv2D(n_dims * 4, 4, 1, 0)\n",
    "            self.conv4 = nn.Conv2D(1, 4, 1, 0)\n",
    "            \n",
    "            self.bn2 = nn.BatchNorm()\n",
    "            self.bn3 = nn.BatchNorm()\n",
    "        \n",
    "    def hybrid_forward(self, F, x, y):\n",
    "        x = F.LeakyReLU(self.conv1(x), slope=0.2)\n",
    "        x = F.LeakyReLU(self.bn2(self.conv2(x)), slope=0.2)\n",
    "        x = F.LeakyReLU(self.bn3(self.conv3(x)), slope=0.2)\n",
    "        \n",
    "        y = F.expand_dims(y, axis=2)\n",
    "        y = F.expand_dims(y, axis=2)\n",
    "        y = F.tile(y, [4,4])\n",
    "        \n",
    "        x = F.concat(x, y, dim=1)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def save(filename):\n",
    "        self.save_params(filename)\n",
    "    \n",
    "    def load(filename, ctx):\n",
    "        self.load_params(filename, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator()\n",
    "netD = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "# initialize the generator and the discriminator\n",
    "netG.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "netD.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "\n",
    "# trainer for the generator and the discriminator\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1, 'beta2': beta2})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1, 'beta2': beta2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.hybridize()\n",
    "netD.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = nd.ones([batch_size, ], ctx=ctx)\n",
    "fake_label = nd.zeros([batch_size, ], ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:speed: 95.58200148054198 samples/s\n",
      "INFO:root:discriminator loss = 1.6231820583343506, generator loss = 4.958664894104004 at iter 0 epoch 0\n",
      "INFO:root:speed: 64.4535934795217 samples/s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    btic = time.time()\n",
    "    i = 0\n",
    "    \n",
    "    for data, labels in test_data:\n",
    "        labels = labels.as_in_context(ctx)\n",
    "        x = data.as_in_context(ctx)\n",
    "        y = nd.one_hot(labels, depth=10)\n",
    "        z = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 1, 1), ctx=ctx)\n",
    "        \n",
    "        y_z = mx.nd.array(np.random.randint(0, 9, size=batch_size))\n",
    "        y_z = nd.one_hot(y_z, depth=10)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        with autograd.record():\n",
    "            output = netD(x, y)\n",
    "            errD_real = loss(output, real_label)\n",
    "            \n",
    "            fake = netG(z, y_z)\n",
    "            output = netD(fake.detach(), y_z)\n",
    "            errD_fake = loss(output, fake_label)\n",
    "            \n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "        trainerD.step(data.shape[0])\n",
    "        \n",
    "        # Train Generator\n",
    "        with autograd.record():\n",
    "            fake = netG(z, y_z)\n",
    "            output = netD(fake, y_z)\n",
    "            errG = loss(output, real_label)\n",
    "            errG.backward()\n",
    "        trainerG.step(data.shape[0])\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            logging.info(f'speed: {batch_size / (time.time() - btic)} samples/s')\n",
    "            logging.info(f'discriminator loss = {nd.mean(errD).asscalar()}, generator loss = {nd.mean(errG).asscalar()} at iter {i} epoch {epoch}')\n",
    "\n",
    "        i = i + 1\n",
    "        btic = time.time()\n",
    "    if epoch % 5 == 0:\n",
    "        netD.save(\"netD.params\")\n",
    "        netG.save(\"netG.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img_arr):\n",
    "    plt.imshow(((img_arr.asnumpy().transpose(1, 2, 0) + 1.0) * 127.5).astype(np.uint8))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 8\n",
    "for i in range(num_image):\n",
    "    latent_z = mx.nd.random_normal(0, 1, shape=(1, latent_z_size, 1, 1), ctx=ctx)\n",
    "    img = netG(latent_z)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    visualize(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
